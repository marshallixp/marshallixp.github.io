<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Deep Learning Study</title>
    <description>Explain the state-of-art research and Track our latest experiments.
</description>
    <link>http://yourdomain.com/</link>
    <atom:link href="http://yourdomain.com/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Wed, 17 Aug 2016 10:48:42 +0800</pubDate>
    <lastBuildDate>Wed, 17 Aug 2016 10:48:42 +0800</lastBuildDate>
    <generator>Jekyll v2.5.0</generator>
    
      <item>
        <title>Semantic Segmentation最新进展</title>
        <description>&lt;h1&gt;Semantic Segmentation基本原理&lt;/h1&gt;

&lt;p&gt;Semantic Segmentation (简称SS)是针对图像进行像素级的分类，即将每一个图像中的像素进行有效识别，从而实现对场景中不同目标，特别是目标之间的边缘进行有效识别的方法。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://github.com/marshallixp/marshallixp.github.io/blob/master/_posts/SemanticSegmentation/data_image.jpg&quot; alt=&quot;data&quot; /&gt;
&lt;img src=&quot;https://github.com/marshallixp/marshallixp.github.io/blob/master/_posts/SemanticSegmentation/label_image.jpg&quot; alt=&quot;label&quot; /&gt;&lt;/p&gt;

&lt;h1&gt;SS最新进展（深度学习）&lt;/h1&gt;
</description>
        <pubDate>Wed, 17 Aug 2016 18:17:00 +0800</pubDate>
        <link>http://yourdomain.com/segmentation/2016/08/17/semantic-segmentation-state-of-art.html</link>
        <guid isPermaLink="true">http://yourdomain.com/segmentation/2016/08/17/semantic-segmentation-state-of-art.html</guid>
        
        
        <category>segmentation</category>
        
      </item>
    
      <item>
        <title>Train Overview</title>
        <description>&lt;p&gt;目前，我们已经基本上完成了SegNet和Fcn两种网络分别在CamVid和PascalVOC2012上的训练。
首先，SegNet较好地完成了CamVid训练，在没有进行样本扩增的条件下，取得了接近文献中所述的训练结果：&lt;/p&gt;

&lt;h1&gt;Iteration 30000:&lt;/h1&gt;

&lt;p&gt;Global acc = 0.85501 Class average acc = 0.5228 Mean Int over Union = 0.44517&lt;/p&gt;

&lt;p&gt;然而，该网络在PascalVOC2012训练集上，出现了一些问题。由于训练集中图片大小不一致，在后面的从pooling层max location坐标返回到进过upsample的数据时候会出现不对应的情况。因而，我们最先修改了网络中的upsample部分，用x2的方式扩大，再crop的方式，实现不同大小的图片数据训练。但是，无法进行多张图片的batch训练。不幸地是，我们发现网络非常难收敛，以至于总是落入局部，导致只能收敛到背景类。&lt;/p&gt;

&lt;p&gt;接下来，我们重新修改了网络实现了以224x224大小的输入，并且从原图中分割出了左上、左下、右上、右下、中五个部分的自图片，构成新的数据集，再采用批量训练的方式进行训练。遗憾的是，SegNet无法获得很好的结果，可能是考虑到该网络更适合全尺寸图片作为输入的方式进行。&lt;/p&gt;

&lt;p&gt;对于Fcn系列网络，我们依照文中所示方法，采用了分阶段的训练模式。先进行Fcn32s的训练，再Fcn16s，最后Fcn8s。根据这样的方法，我们在两个数据库中获得的结果如下：
&lt;em&gt;CamVid:&lt;/em&gt;
Fcn32s # Iteration 100000:
Global acc = 0.80453 Class average acc = 0.47098 Mean Int over Union = 0.3897
Fcn16s # Iteration 100000:
Global acc = 0.81284 Class average acc = 0.4834 Mean Int over Union = 0.40864
Fcn8s 出现了网络倒退的情况，理论上较Fcn16s应没有太大的提升。&lt;/p&gt;

&lt;p&gt;&lt;em&gt;PascalVOC2012:&lt;/em&gt; (我们选取训练中最优结果)
Fcn32s&lt;/p&gt;

&lt;blockquote&gt;&lt;blockquote&gt;&lt;blockquote&gt;&lt;p&gt;2016-08-15 10:59:04.305616 Begin seg tests
2016-08-15 11:03:10.741634 Iteration 24000 loss 0.527342150643
2016-08-15 11:03:10.741799 Iteration 24000 overall accuracy 0.842504675537
2016-08-15 11:03:10.741979 Iteration 24000 mean accuracy 0.740968773048
2016-08-15 11:03:10.742108 Iteration 24000 mean IU 0.497978761185
2016-08-15 11:03:10.742194 Iteration 24000 fwavacc 0.7562668472066
文中的结果IU为59.4&lt;/p&gt;&lt;/blockquote&gt;&lt;/blockquote&gt;&lt;/blockquote&gt;

&lt;p&gt;Fcn16s&lt;/p&gt;

&lt;blockquote&gt;&lt;blockquote&gt;&lt;blockquote&gt;&lt;p&gt;2016-08-15 12:25:01.189435 Begin seg tests
2016-08-15 12:27:44.222110 Iteration 24000 loss 0.435023135992
2016-08-15 12:27:44.222216 Iteration 24000 overall accuracy 0.874859384552
2016-08-15 12:27:44.222333 Iteration 24000 mean accuracy 0.715943696788
2016-08-15 12:27:44.222608 Iteration 24000 mean IU 0.536879623865
2016-08-15 12:27:44.222697 Iteration 24000 fwavacc 0.796204639853
文中的结果IU为62.4&lt;/p&gt;&lt;/blockquote&gt;&lt;/blockquote&gt;&lt;/blockquote&gt;

&lt;p&gt;Fcn8s
结果目前还没有出来。文中结果IU为62.7&lt;/p&gt;

&lt;p&gt;总结：
Fcn系列网络的缺点：
1) Fcn的Deconvolution层学习upsample它的输入特征图机制并没有保留Spatial correlation.
2) 由于Fcn最多只调用到conv3层，没有用到精度更高的特征图，会导致失去边缘信息
3) 重用encoder部分的特征图，增大了内存的开销
4) 必须采用分阶段训练方法，也就是说如果最初的Fcn32s训练不好，最终的Fcn8s训练也不会有太大的提升。&lt;/p&gt;
</description>
        <pubDate>Tue, 16 Aug 2016 23:47:00 +0800</pubDate>
        <link>http://yourdomain.com/segmentation/2016/08/16/train-overview.html</link>
        <guid isPermaLink="true">http://yourdomain.com/segmentation/2016/08/16/train-overview.html</guid>
        
        
        <category>segmentation</category>
        
      </item>
    
      <item>
        <title>Train on Pascal(4)</title>
        <description>&lt;p&gt;根据过去近两周的工作，又仔细地研读了相关论文，针对PascalVOC2012数据集，采用了依照原论文的分阶段训练方式进行。首先，重新矫正了Fcn32s的网络参数和solver.prototxt，设置为20的iter_size，即用大小为20的batch_size进行网络参数更新。拟采用先进行Fcn32s的训练（Fcn-vgg16），然后进行Fcn16s(导入Fcn32s训练结果)训练，最后将Fcn16s训练结果导入Fcn8s完成三步分阶段训练。&lt;/p&gt;

&lt;p&gt;关于L.Python层的batch_size修改问题，不仅可以从前文所说的进行修改，也可以在module对于对应的py文件中添加slef.batch_size= param['batch_size']进行更改，同时在forward函数中进行top的相应修改。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Pascal VOC 2012 训练步骤：&lt;/strong&gt;
Fcn32s -&gt; Fcn16s -&gt; Fcn8s 或 Fcn32s -&gt; Fcn8s&lt;/p&gt;

&lt;p&gt;Step1. 首先对Fcn32s进行训练，主要参数如下：
base_lr: 1e-4
momentum: 0.9
iter_size: 20
max_iter: 100000
weight_decay: 0.0005&lt;/p&gt;

&lt;p&gt;较优训练结果：&lt;/p&gt;

&lt;blockquote&gt;&lt;blockquote&gt;&lt;blockquote&gt;&lt;p&gt;2016-08-15 10:59:04.305616 Begin seg tests
2016-08-15 11:03:10.741634 Iteration 24000 loss 0.527342150643
2016-08-15 11:03:10.741799 Iteration 24000 overall accuracy 0.842504675537
2016-08-15 11:03:10.741979 Iteration 24000 mean accuracy 0.740968773048
2016-08-15 11:03:10.742108 Iteration 24000 mean IU 0.497978761185
2016-08-15 11:03:10.742194 Iteration 24000 fwavacc 0.7562668472066&lt;/p&gt;&lt;/blockquote&gt;&lt;/blockquote&gt;&lt;/blockquote&gt;

&lt;p&gt;Step2. 训练Fcn16s网络，将Fcn32s网络训练结果导入，主要参数如下：
base_lr: 1e-6
momentum: 0.9
iter_size: 1
max_iter: 100000
weight_decay: 0.0005
较优训练结果：&lt;/p&gt;

&lt;blockquote&gt;&lt;blockquote&gt;&lt;blockquote&gt;&lt;p&gt;2016-08-15 12:25:01.189435 Begin seg tests
2016-08-15 12:27:44.222110 Iteration 24000 loss 0.435023135992
2016-08-15 12:27:44.222216 Iteration 24000 overall accuracy 0.874859384552
2016-08-15 12:27:44.222333 Iteration 24000 mean accuracy 0.715943696788
2016-08-15 12:27:44.222608 Iteration 24000 mean IU 0.536879623865
2016-08-15 12:27:44.222697 Iteration 24000 fwavacc 0.796204639853
可以看到，从统计数据上来说较前一模型有4%左右的提升。&lt;/p&gt;&lt;/blockquote&gt;&lt;/blockquote&gt;&lt;/blockquote&gt;

&lt;p&gt;Step3. 训练Fcn8s网络，将Fcn16s的训练结果导入，
base_lr: 1e-8
momentum: 0.99
iter_size: 20
max_iter: 100000
weight_decay: 0.0005
较优训练结果：&lt;/p&gt;
</description>
        <pubDate>Fri, 12 Aug 2016 22:20:00 +0800</pubDate>
        <link>http://yourdomain.com/segmentation/2016/08/12/train-on-pascal(4).html</link>
        <guid isPermaLink="true">http://yourdomain.com/segmentation/2016/08/12/train-on-pascal(4).html</guid>
        
        
        <category>segmentation</category>
        
      </item>
    
      <item>
        <title>Train on Pascal(3)</title>
        <description>&lt;p&gt;通过测试，验证了通过voc_layer均值化后的data和转换成1x1xHxW的label数据的正确。label是包含0~20以及255的同尺寸数据。label:0对应background，而1~20对应不同目标类别。现在的问题是，运用segnet网络训练后，只能收敛到背景分类。&lt;/p&gt;

&lt;p&gt;目前，已经完成的训练及测试包括：
a. Fcn32s on Pascal
b. Fcn32s on CamVid
c. SegNet on CamVid
以上都有接近文章的效果&lt;/p&gt;

&lt;p&gt;而SegNet on Pascal依然无法实现，正在测试几种改进方案：
1）增加Dropout
2）利用basic segnet进行测试
3）生成符合DenseImageDataLayer的label数据集
4）只采用少量（～10）样本进行训练&lt;/p&gt;

&lt;p&gt;方案1）增加了两种不同的dropout层，全覆盖和半覆盖，包括结合不同的学习速率进行训练，依然未能解决问题。&lt;/p&gt;

&lt;p&gt;方案2）basic segnet似乎也未见效，依然落入局部最小值，输出全为背景标记。&lt;/p&gt;

&lt;p&gt;方案3）通过在网络测试过程中，获取的经过处理后的label图片，保存至SegmentationClass-SegNet，再调用DenseImageDataLayer进行读取。经测试，依然无效。&lt;/p&gt;

&lt;p&gt;方案4）采用10个训练样本，能看到loss是在不断减小，且经过大约5000次迭代(1e-4, 0.9)以后，不全是输出到背景。且通过更改weight_decay=0.5，能收敛到非背景目标。&lt;/p&gt;

&lt;p&gt;至此，我们采取的大多数测试并不能使网络有效收敛，于是，我们继续采用原文中的处理方法，将图片crop成固定大小224x224，并且通过采样不同区域，进行augmentation。再采用固定每层尺寸大小的网络，即不使用crop层，进行测试。&lt;/p&gt;

&lt;p&gt;改回upsample???&lt;/p&gt;
</description>
        <pubDate>Tue, 02 Aug 2016 19:31:00 +0800</pubDate>
        <link>http://yourdomain.com/segmentation/2016/08/02/train-on-pascal(3).html</link>
        <guid isPermaLink="true">http://yourdomain.com/segmentation/2016/08/02/train-on-pascal(3).html</guid>
        
        
        <category>segmentation</category>
        
      </item>
    
      <item>
        <title>lsd-slam test</title>
        <description>&lt;p&gt;some words before...&lt;/p&gt;

&lt;p&gt; &lt;strong&gt;semantics are necessary to build bigger and better SLAM systems.&lt;/strong&gt;&lt;br/&gt;
 &lt;strong&gt;Robotics is the killer application of SLAM&lt;/strong&gt;&lt;br/&gt;
 &lt;strong&gt;Will end-to-end learning soon replace the mostly manual labor involved in building today’s SLAM systems?. &lt;/strong&gt;&lt;br/&gt;
 -&gt;  Integrating semantics into SLAM is often talk about, but it is easier said than done. Moreno's PhD thesis: Dense Semantic SLAM&lt;/p&gt;

&lt;p&gt; &lt;strong&gt;SLAM (construction) &lt;---help---&gt; Deep Learning (perception)&lt;/strong&gt;
 large-scale &quot;correspondence engines&quot; -&gt; large-scale datasets&lt;/p&gt;

&lt;p&gt;调试过程：
1. 确认摄像头是或否工作，运用cheese
2. 安装ros下的库uvc_camera，确认摄像头所对应设备号/dev/video*
3. 在uvc_camera下新建launch文件夹，再新建uvc_camera_node.launch文件，复制以下代码
&lt;launch&gt;&lt;arg name=&quot;device&quot; default=&quot;/dev/video0&quot;/&gt;
   &lt;node pkg=&quot;uvc_camera&quot; type=&quot;camera_node&quot; name=&quot;uvc_camera&quot; output=&quot;screen&quot;&gt;
    &lt;param name=&quot;width&quot; type=&quot;int&quot; value=&quot;640&quot; /&gt;
    &lt;param name=&quot;height&quot; type=&quot;int&quot; value=&quot;480&quot; /&gt;
    &lt;param name=&quot;fps&quot; type=&quot;int&quot; value=&quot;30&quot; /&gt;
    &lt;param name=&quot;frame&quot; type=&quot;string&quot; value=&quot;wide_stereo&quot; /&gt;
    &lt;param name=&quot;device&quot; type=&quot;string&quot; value=&quot;/dev/video0&quot; /&gt;
  &lt;/node&gt;
&lt;/launch&gt;
4. 运行roscore
5. 运行rosrun lsd_slam_viewer viewer
6. 运行roslaunch uvc_camera uvc_camera_node.launch
7. 运行rosrun lsd_slam_core live_slam /image:=image_raw _calib:=~/ROS_DEV/rosbuild_ws/package_dir/lsd_slam/lsd_slam_core/calib/FOVxxx.cfg&lt;/p&gt;
</description>
        <pubDate>Sat, 30 Jul 2016 00:44:59 +0800</pubDate>
        <link>http://yourdomain.com/slam/2016/07/30/lsd-slam-run-on-usbcam.html</link>
        <guid isPermaLink="true">http://yourdomain.com/slam/2016/07/30/lsd-slam-run-on-usbcam.html</guid>
        
        
        <category>slam</category>
        
      </item>
    
      <item>
        <title>Train on Pascal(2)</title>
        <description>&lt;p&gt;由于前一次训练中发现网络并没有收敛，经过查阅资料，我们决定采用以下调整方案：&lt;br/&gt;
1) Reduce learning rate by a factor of 10&lt;br/&gt;
2) Normalize softmax loss (divide with the number of pixels -&gt; normalize: true)&lt;br/&gt;
3) Try net surgery&lt;br/&gt;
4) mean RGB / BGR ?&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;要点：&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;a) Make sure you do not make the model to learn from the background (ignore_label=255)&lt;br/&gt;
b) IU score / pixel-wise accuracy are more important
c) Check each layer to see it's initialized with correct values&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Fcn32s Training&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;根据调整方案1），目前采用fixed的学习率，取值1e-9。根据2），将softmaxloss层的normalize设置为true。根据修改后的参数模型，经过4000次迭代以后，我们发现loss是在不断减小，说明模型可以收敛，但是主要的指标参数依然没有改变，需要等待进一步的结果。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt; 2016-07-27 15:58:21.062000 Iteration 4000 loss 3.04448500594  
&amp;gt;&amp;gt;&amp;gt; 2016-07-27 15:58:21.062184 Iteration 4000 overall accuracy 0.733180213097  
&amp;gt;&amp;gt;&amp;gt; 2016-07-27 15:58:21.062357 Iteration 4000 mean accuracy 0.047619047619  
&amp;gt;&amp;gt;&amp;gt; 2016-07-27 15:58:21.062504 Iteration 4000 mean IU 0.0349133434808  
&amp;gt;&amp;gt;&amp;gt; 2016-07-27 15:58:21.062591 Iteration 4000 fwavacc 0.537553224877  
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;当从32000次迭代结果恢复以后，我们发现网络的损失是以很小的数值下降，约为3e-5的减小值。但是，主要指标依然没有变化。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt; 2016-07-28 12:56:20.636460 Begin seg tests
&amp;gt;&amp;gt;&amp;gt; 2016-07-28 12:59:02.790584 Iteration 48000 loss 3.04407284242
&amp;gt;&amp;gt;&amp;gt; 2016-07-28 12:59:02.790747 Iteration 48000 overall accuracy 0.733180213097
&amp;gt;&amp;gt;&amp;gt; 2016-07-28 12:59:02.790932 Iteration 48000 mean accuracy 0.047619047619
&amp;gt;&amp;gt;&amp;gt; 2016-07-28 12:59:02.791069 Iteration 48000 mean IU 0.0349133434808
&amp;gt;&amp;gt;&amp;gt; 2016-07-28 12:59:02.791161 Iteration 48000 fwavacc 0.537553224877
&amp;gt;&amp;gt;&amp;gt; 2016-07-28 13:21:27.470571 Begin seg tests
&amp;gt;&amp;gt;&amp;gt; 2016-07-28 13:24:08.706496 Iteration 52000 loss 3.04403515862
&amp;gt;&amp;gt;&amp;gt; 2016-07-28 13:24:08.706656 Iteration 52000 overall accuracy 0.733180213097
&amp;gt;&amp;gt;&amp;gt; 2016-07-28 13:24:08.706831 Iteration 52000 mean accuracy 0.047619047619
&amp;gt;&amp;gt;&amp;gt; 2016-07-28 13:24:08.706970 Iteration 52000 mean IU 0.0349133434808
&amp;gt;&amp;gt;&amp;gt; 2016-07-28 13:24:08.707063 Iteration 52000 fwavacc 0.537553224877  
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;对网络层进行检查，我们很遗憾地发现fc6_conv, fc7_conv, score_fr层，并没有被初始化，也没有训练更新，这是目前网络无法收敛的原因。&lt;/p&gt;

&lt;p&gt;根据上述分析，采取如下调整：
1) vgg16相关的层冻结，对fc6_conv, fc7_conv, score_fr, upscore激活学习参数,并且初始化，如下：&lt;br/&gt;
param {
    lr_mult: 1
    decay_mult: 1
}&lt;br/&gt;
param {
    lr_mult: 2
    decay_mult: 0
}&lt;br/&gt;
convolution_param {
    num_output: 4096
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: &quot;gaussian&quot;
      std: 0.01
    }
    bias_filler {
      type: &quot;constant&quot;
      value: 0.1
    }
}&lt;/p&gt;

&lt;p&gt;2）采用fixed的学习率1e-10，monentum为0.99。在经过200次迭代之后，我们观察相关层的变化情况。然而，发现除了初始化成功外，依然没有进行训练，即相关层的权重几乎没有改变（1000次迭代，除了score_fr层有微小改变）。&lt;/p&gt;

&lt;p&gt;考虑到可能是学习率设置太小，现将学习率改为1e-6, momentum为0.9，再次进行训练。发现果然如预期，除了固定权重层（vgg对应）以外，其余各层权重均开始改变。设想训练参数及网络模型有效，需要进行再次训练验证。同时，根据文章中的参数设置，我们重新设置训练主要参数如下：&lt;br/&gt;
lr_policy: &quot;fixed&quot;&lt;br/&gt;
base_lr: 1e-4&lt;br/&gt;
momentum: 0.9&lt;br/&gt;
weight_decay: 0.0005&lt;br/&gt;
于是，结果如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt; 2016-07-28 15:37:43.526054 Begin seg tests
&amp;gt;&amp;gt;&amp;gt; 2016-07-28 15:40:30.566007 Iteration 4000 loss 0.778730130796
&amp;gt;&amp;gt;&amp;gt; 2016-07-28 15:40:30.566297 Iteration 4000 overall accuracy 0.833765982794
&amp;gt;&amp;gt;&amp;gt; 2016-07-28 15:40:30.566349 Iteration 4000 mean accuracy 0.654612851421
&amp;gt;&amp;gt;&amp;gt; 2016-07-28 15:40:30.566486 Iteration 4000 mean IU 0.450926431181
&amp;gt;&amp;gt;&amp;gt; 2016-07-28 15:40:30.566580 Iteration 4000 fwavacc 0.742218942131
&amp;gt;&amp;gt;&amp;gt; 2016-07-28 15:53:21.709648 Begin seg tests
&amp;gt;&amp;gt;&amp;gt; 2016-07-28 15:56:08.182363 Iteration 8000 loss 0.865841977427
&amp;gt;&amp;gt;&amp;gt; 2016-07-28 15:56:08.182477 Iteration 8000 overall accuracy 0.804960917114
&amp;gt;&amp;gt;&amp;gt; 2016-07-28 15:56:08.182606 Iteration 8000 mean accuracy 0.723366231692
&amp;gt;&amp;gt;&amp;gt; 2016-07-28 15:56:08.182786 Iteration 8000 mean IU 0.450797861465
&amp;gt;&amp;gt;&amp;gt; 2016-07-28 15:56:08.182920 Iteration 8000 fwavacc 0.715707726933
&amp;gt;&amp;gt;&amp;gt; 2016-07-28 16:08:59.654618 Begin seg tests
&amp;gt;&amp;gt;&amp;gt; 2016-07-28 16:11:45.822145 Iteration 12000 loss 0.72744285975
&amp;gt;&amp;gt;&amp;gt; 2016-07-28 16:11:45.822326 Iteration 12000 overall accuracy 0.829063382524
&amp;gt;&amp;gt;&amp;gt; 2016-07-28 16:11:45.822399 Iteration 12000 mean accuracy 0.728383144052
&amp;gt;&amp;gt;&amp;gt; 2016-07-28 16:11:45.822697 Iteration 12000 mean IU 0.470663378357
&amp;gt;&amp;gt;&amp;gt; 2016-07-28 16:11:45.822794 Iteration 12000 fwavacc 0.738958147784
&amp;gt;&amp;gt;&amp;gt; 2016-07-28 16:24:43.682142 Begin seg tests
&amp;gt;&amp;gt;&amp;gt; 2016-07-28 16:27:32.582254 Iteration 16000 loss 0.671988376899
&amp;gt;&amp;gt;&amp;gt; 2016-07-28 16:27:32.582414 Iteration 16000 overall accuracy 0.834907019939
&amp;gt;&amp;gt;&amp;gt; 2016-07-28 16:27:32.582577 Iteration 16000 mean accuracy 0.730903583042
&amp;gt;&amp;gt;&amp;gt; 2016-07-28 16:27:32.582713 Iteration 16000 mean IU 0.474480346083
&amp;gt;&amp;gt;&amp;gt; 2016-07-28 16:27:32.582808 Iteration 16000 fwavacc 0.746916759749
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可见，最终主要指标都出现大幅提升，说明训练有效！&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;SegNet Training&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;根据调整方案1)，采用fixed的学习率1e-10，monentum为0.99。根据2），将softmaxloss层的normalize设置为true。&lt;br/&gt;
同样，经过4000次迭代以后，我们发现修改后的参数模型，loss可以不断减小，即表示可以收敛，而且收敛速度快于Fcn32s网络，但是最主要的指标参数也依然没有出现变化，需等待进一步训练结果。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt; 2016-07-27 16:36:01.449254 Iteration 4000 loss 3.04294351251  
&amp;gt;&amp;gt;&amp;gt; 2016-07-27 16:36:01.449524 Iteration 4000 overall accuracy 0.733180213097  
&amp;gt;&amp;gt;&amp;gt; 2016-07-27 16:36:01.449573 Iteration 4000 mean accuracy 0.047619047619  
&amp;gt;&amp;gt;&amp;gt; 2016-07-27 16:36:01.449706 Iteration 4000 mean IU 0.0349133434808  
&amp;gt;&amp;gt;&amp;gt; 2016-07-27 16:36:01.449798 Iteration 4000 fwavacc 0.537553224877  
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;由于之前的Fcn32s网络实现了有效训练，我们将相关调整也作用于SegNet网络上（选用相同的训练参数），测试结果。&lt;/p&gt;

&lt;p&gt;正如预期，SegNet也可以较为快速的收敛，并且相应层参数均发生改变。最后，我们对整个网络进行训练测试，其结果如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt; 2016-07-28 16:47:44.193496 Iteration 4000 loss 1.34012441367
&amp;gt;&amp;gt;&amp;gt; 2016-07-28 16:47:44.193629 Iteration 4000 overall accuracy 0.733180213097
&amp;gt;&amp;gt;&amp;gt; 2016-07-28 16:47:44.193757 Iteration 4000 mean accuracy 0.047619047619
&amp;gt;&amp;gt;&amp;gt; 2016-07-28 16:47:44.194040 Iteration 4000 mean IU 0.0349133434808
&amp;gt;&amp;gt;&amp;gt; 2016-07-28 16:47:44.194139 Iteration 4000 fwavacc 0.537553224877
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;结果发现主要参数指标并没有改变，对相关层进行检查，发现decoder层(conv1_1_D)权重并未有效地学习。然而，对conv1_1_D的权重进行初始化，依然不能使得网络有效地收敛，如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt; 2016-07-28 19:19:44.126946 Iteration 24254 loss 1.30797043911
&amp;gt;&amp;gt;&amp;gt; 2016-07-28 19:19:44.127122 Iteration 24254 overall accuracy 0.733161065479
&amp;gt;&amp;gt;&amp;gt; 2016-07-28 19:19:44.127300 Iteration 24254 mean accuracy 0.0476180853631
&amp;gt;&amp;gt;&amp;gt; 2016-07-28 19:19:44.127435 Iteration 24254 mean IU 0.0349127414014
&amp;gt;&amp;gt;&amp;gt; 2016-07-28 19:19:44.127536 Iteration 24254 fwavacc 0.537539625039
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;接下来，调整网络模型，设置convolution层的参数为type='gaussian', std=0.01。我们发现依然很难收敛。于是，为了验证添加多个crop层是否正确，通过之前已经成功在CamVid训练集上测试的SegNet网络，再使用更改后的Caffe在新的网络上（添加多个crop层）进行测试。我们发现同样在CamVid上训练，SegNet(1e-3)似乎能有比Fcn32s(1e-4)更快的收敛速度。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;小结&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;对于fcn32s网络来说，由于一开始并没有弄清楚各个训练参数和网络模型参数的意思，始终将vgg16对应层进入训练，相反最后的score_fr和upscore层并没有进行训练;除此以外，除vgg16对应层外的如fc6_conv等并没有有效初始化，无法实现参数更新。而且，当训练参数如base_lr设置太小（如1e-10）也会导致训练收敛速度过慢。当然，normalize softmax loss也是必须的。&lt;/p&gt;

&lt;p&gt;PS:　对于fcn32s相较于SegNet来说，decoder部分层数少，因而训练过程速度要快于后者。&lt;/p&gt;
</description>
        <pubDate>Wed, 27 Jul 2016 23:09:00 +0800</pubDate>
        <link>http://yourdomain.com/segmentation/2016/07/27/train-on-pascal(2).html</link>
        <guid isPermaLink="true">http://yourdomain.com/segmentation/2016/07/27/train-on-pascal(2).html</guid>
        
        
        <category>segmentation</category>
        
      </item>
    
      <item>
        <title>Train on Pascal(1)</title>
        <description>&lt;p&gt;&lt;strong&gt;SegNet Training&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Step1. 不训练（没有反向过程），直接测试&lt;/em&gt;&lt;br/&gt;
1）不用pretrained vgg16模型&lt;br/&gt;
2）使用pretrained vgg16模型&lt;br/&gt;
其中，1）结果如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt;2016-07-25 15:29:18.270980 Iteration 0 loss 87.3365001902  
&amp;gt;&amp;gt;&amp;gt;2016-07-25 15:29:18.271152 Iteration 0 overall accuracy 0.733180213097  
&amp;gt;&amp;gt;&amp;gt;2016-07-25 15:29:18.271215 Iteration 0 mean accuracy 0.047619047619  
&amp;gt;&amp;gt;&amp;gt;2016-07-25 15:29:18.271508 Iteration 0 mean IU 0.0349133434808  
&amp;gt;&amp;gt;&amp;gt;2016-07-25 15:29:18.271601 Iteration 0 fwavacc 0.537553224877  
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;相应，2）结果如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt;2016-07-25 15:35:54.661197 Iteration 0 loss 87.3365001902  
&amp;gt;&amp;gt;&amp;gt;2016-07-25 15:35:54.661321 Iteration 0 overall accuracy 0.733180213097  
&amp;gt;&amp;gt;&amp;gt;2016-07-25 15:35:54.661488 Iteration 0 mean accuracy 0.047619047619  
&amp;gt;&amp;gt;&amp;gt;2016-07-25 15:35:54.661621 Iteration 0 mean IU 0.0349133434808  
&amp;gt;&amp;gt;&amp;gt;2016-07-25 15:35:54.661709 Iteration 0 fwavacc 0.537553224877  
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;很明显，无论是否采用vgg16对没有经过训练网络的结果没有影响。&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Step2. 训练，再测试&lt;/em&gt;&lt;br/&gt;
solver.protoxt中参数根据文章中的设置如下：&lt;br/&gt;
train_net: &quot;train.prototxt&quot;&lt;br/&gt;
test_net: &quot;val.prototxt&quot;&lt;br/&gt;
test_initialization: false&lt;br/&gt;
test_iter: 736&lt;br/&gt;
test_interval: 999999999&lt;br/&gt;
display: 20&lt;br/&gt;
average_loss: 20&lt;br/&gt;
lr_policy: &quot;fixed&quot;&lt;br/&gt;
base_lr: 1e-4&lt;br/&gt;
momentum: 0.9&lt;br/&gt;
iter_size: 1&lt;br/&gt;
max_iter: 100000&lt;br/&gt;
weight_decay: 0.0005&lt;br/&gt;
snapshot: 4000&lt;br/&gt;
snapshot_prefix: &quot;snapshot/segnet&quot;&lt;br/&gt;
solver_mode: GPU&lt;/p&gt;

&lt;p&gt;1）使用pretrained vgg16模型，训练4000次，结果如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt;2016-07-26 12:23:04.827459 Iteration 4000 loss 1.31175746871  
&amp;gt;&amp;gt;&amp;gt;2016-07-26 12:23:04.827577 Iteration 4000 overall accuracy 0.733180213097  
&amp;gt;&amp;gt;&amp;gt;2016-07-26 12:23:04.827639 Iteration 4000 mean accuracy 0.047619047619  
&amp;gt;&amp;gt;&amp;gt;2016-07-26 12:23:04.827855 Iteration 4000 mean IU 0.0349133434808  
&amp;gt;&amp;gt;&amp;gt;2016-07-26 12:23:04.828067 Iteration 4000 fwavacc 0.537553224877  
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在经过4000次迭代，大约2.5倍样本集后，loss在缓慢下降，但是其他测量结果没有改变。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt;2016-07-26 17:29:48.209541 Iteration 48000 loss 1.56178289191  
&amp;gt;&amp;gt;&amp;gt;2016-07-26 17:29:48.209808 Iteration 48000 overall accuracy 0.733170522908  
&amp;gt;&amp;gt;&amp;gt;2016-07-26 17:29:48.209855 Iteration 48000 mean accuracy 0.0476187852268  
&amp;gt;&amp;gt;&amp;gt;2016-07-26 17:29:48.209980 Iteration 48000 mean IU 0.0349132915075  
&amp;gt;&amp;gt;&amp;gt;2016-07-26 17:29:48.210064 Iteration 48000 fwavacc 0.537546775601  
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在经过48000次迭代以后，loss并没有收敛，训练失败，待续。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Fcn32s Training&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;首先，我们下载了训练好的模型fcn32s-heavy-model，发现经过finetune以后，结果会更好。&lt;br/&gt;
&lt;em&gt;Fcn32s fine-tune with pretrained heavy model&lt;/em&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt;2016-07-11 17:11:40.982484 Iteration 4000 loss 40536.5665925  
&amp;gt;&amp;gt;&amp;gt;2016-07-11 17:11:40.982576 Iteration 4000 overall accuracy 0.924534222757  
&amp;gt;&amp;gt;&amp;gt;2016-07-11 17:11:40.982608 Iteration 4000 mean accuracy 0.789070139032   
&amp;gt;&amp;gt;&amp;gt;2016-07-11 17:11:40.982729 Iteration 4000 mean IU 0.68489801572  
&amp;gt;&amp;gt;&amp;gt;2016-07-11 17:11:40.982804 Iteration 4000 fwavacc 0.867180920774  

&amp;gt;&amp;gt;&amp;gt;2016-07-11 17:34:39.726955 Iteration 8000 loss 40918.7736482  
&amp;gt;&amp;gt;&amp;gt;2016-07-11 17:34:39.727035 Iteration 8000 overall accuracy 0.928679202249  
&amp;gt;&amp;gt;&amp;gt;2016-07-11 17:34:39.727064 Iteration 8000 mean accuracy 0.812085149284  
&amp;gt;&amp;gt;&amp;gt;2016-07-11 17:34:39.727181 Iteration 8000 mean IU 0.698756970877  
&amp;gt;&amp;gt;&amp;gt;2016-07-11 17:34:39.727255 Iteration 8000 fwavacc 0.873438191274  
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;em&gt;Fcn32s + pretrained heavy model without training&lt;/em&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt;2016-07-11 17:40:52.292152 Iteration 0 loss 45737.5351437  
&amp;gt;&amp;gt;&amp;gt;2016-07-11 17:40:52.292247 Iteration 0 overall accuracy 0.926090782406  
&amp;gt;&amp;gt;&amp;gt;2016-07-11 17:40:52.292278 Iteration 0 mean accuracy 0.817075271365  
&amp;gt;&amp;gt;&amp;gt;2016-07-11 17:40:52.292399 Iteration 0 mean IU 0.695001155057  
&amp;gt;&amp;gt;&amp;gt;2016-07-11 17:40:52.292475 Iteration 0 fwavacc 0.869301769793  
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;其次，我们利用pretrained VGG16进行训练。 目前得到的结果显示，loss会降低，但是其他测量结果并没有发生改变，如下:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt;2016-07-26 12:48:33.904036 Iteration 8000 loss 3916726.69319  
&amp;gt;&amp;gt;&amp;gt;2016-07-26 12:48:33.904141 Iteration 8000 overall accuracy 0.733180213097  
&amp;gt;&amp;gt;&amp;gt;2016-07-26 12:48:33.904256 Iteration 8000 mean accuracy 0.047619047619  
&amp;gt;&amp;gt;&amp;gt;2016-07-26 12:48:33.904529 Iteration 8000 mean IU 0.0349133434808  
&amp;gt;&amp;gt;&amp;gt;2016-07-26 12:48:33.904619 Iteration 8000 fwavacc 0.53755322487  

&amp;gt;&amp;gt;&amp;gt;2016-07-26 13:39:00.477857 Iteration 16000 loss 3646240.50901  
&amp;gt;&amp;gt;&amp;gt;2016-07-26 13:39:00.477998 Iteration 16000 overall accuracy 0.733180213097
&amp;gt;&amp;gt;&amp;gt;2016-07-26 13:39:00.478118 Iteration 16000 mean accuracy 0.047619047619  
&amp;gt;&amp;gt;&amp;gt;2016-07-26 13:39:00.478241 Iteration 16000 mean IU 0.0349133434808  
&amp;gt;&amp;gt;&amp;gt;2016-07-26 13:39:00.478323 Iteration 16000 fwavacc 0.537553224877  

&amp;gt;&amp;gt;&amp;gt;2016-07-26 17:03:43.480082 Iteration 48000 loss 3076769.60242  
&amp;gt;&amp;gt;&amp;gt;2016-07-26 17:03:43.480186 Iteration 48000 overall accuracy 0.733180213097
&amp;gt;&amp;gt;&amp;gt;2016-07-26 17:03:43.480288 Iteration 48000 mean accuracy 0.047619047619  
&amp;gt;&amp;gt;&amp;gt;2016-07-26 17:03:43.480508 Iteration 48000 mean IU 0.0349133434808  
&amp;gt;&amp;gt;&amp;gt;2016-07-26 17:03:43.480592 Iteration 48000 fwavacc 0.537553224877  
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;经过近50000次的训练，发现其中loss并没有收敛，而且另外4个指标也完全没有任何改变，和未经过训练的结果相同。可见，这里存在什么问题还没有弄清楚，待续。&lt;/p&gt;
</description>
        <pubDate>Wed, 27 Jul 2016 01:09:59 +0800</pubDate>
        <link>http://yourdomain.com/segmentation/2016/07/27/train-on-pascal(1).html</link>
        <guid isPermaLink="true">http://yourdomain.com/segmentation/2016/07/27/train-on-pascal(1).html</guid>
        
        
        <category>segmentation</category>
        
      </item>
    
      <item>
        <title>Train on CamVid</title>
        <description>&lt;p&gt;原有camvid拥有33个类：&lt;/p&gt;

&lt;p&gt;64 128 64   Animal
192 0 128   Archway
0 128 192   Bicyclist
0 128 64    Bridge
128 0 0     Building
64 0 128    Car
64 0 192    CartLuggagePram
192 128 64  Child
192 192 128 Column_Pole
64 64 128   Fence
128 0 192   LaneMkgsDriv
192 0 64    LaneMkgsNonDriv
128 128 64  Misc_Text
192 0 192   MotorcycleScooter
128 64 64   OtherMoving
64 192 128  ParkingBlock
64 64 0     Pedestrian
128 64 128  Road
128 128 192 RoadShoulder
0 0 192     Sidewalk
192 128 128 SignSymbol
128 128 128 Sky
64 128 192  SUVPickupTruck
0 0 64      TrafficCone
0 64 64     TrafficLight
192 64 128  Train
128 128 0   Tree
192 128 192 Truck_Bus
64 0 64     Tunnel
192 192 0   VegetationMisc
0 0 0       Void
64 192 0    Wall&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;SegNet postprocess&lt;/strong&gt;
python /Segnet/Scripts/compute_bn_statistics.py /SegNet/Models/segnet_train.prototxt /SegNet/Models/Training/segnet_iter_10000.caffemodel /Segnet/Models/Inference/&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;SegNet + Pretrained VGG16&lt;/strong&gt;&lt;/p&gt;

&lt;h1&gt;Iteration 10000:&lt;/h1&gt;

&lt;p&gt;Global acc = 0.85101 Class average acc = 0.46322 Mean Int over Union = 0.40203&lt;/p&gt;

&lt;h1&gt;Iteration 20000:&lt;/h1&gt;

&lt;p&gt;Global acc = 0.85167 Class average acc = 0.52274 Mean Int over Union = 0.44069&lt;/p&gt;

&lt;h1&gt;Iteration 30000:&lt;/h1&gt;

&lt;p&gt;Global acc = 0.85501 Class average acc = 0.5228 Mean Int over Union = 0.44517&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;SegNet modified (修正crop层，可以自动实现不同层之间的匹配)&lt;/strong&gt;&lt;/p&gt;

&lt;h1&gt;Iteration 26000:&lt;/h1&gt;

&lt;p&gt;Global acc = 0.81241 Class average acc = 0.47571 Mean Int over Union = 0.3939
低于原有模型训练结果，或许跟参数设置有关系。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Fcn32s + Pretrained VGG16&lt;/strong&gt;&lt;/p&gt;

&lt;h1&gt;Iteration 56000:&lt;/h1&gt;

&lt;p&gt;Global acc = 0.79462 Class average acc = 0.4331 Mean Int over Union = 0.35841&lt;/p&gt;

&lt;h1&gt;Iteration 100000:&lt;/h1&gt;

&lt;p&gt;Global acc = 0.80453 Class average acc = 0.47098 Mean Int over Union = 0.38977&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Fcn16s + Pretrained Fcn32s&lt;/strong&gt;&lt;/p&gt;

&lt;h1&gt;Iteration 100000:&lt;/h1&gt;

&lt;p&gt;Global acc = 0.81284 Class average acc = 0.4834 Mean Int over Union = 0.40864&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Fcn8s + Pretrained Fcn16s&lt;/strong&gt;
网络出现退化情况&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Fcn8s + Pretrained VGG16&lt;/strong&gt;&lt;/p&gt;

&lt;h1&gt;Iteration 56000:&lt;/h1&gt;

&lt;p&gt;Global acc = 0.70828 Class average acc = 0.36595 Mean Int over Union = 0.28398&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;总结：&lt;/strong&gt;
在针对道路场景的语义分割训练中，我们主要参考了Fcn[1], SegNet[2], ENet[3]，这三篇文章。其中，Fcn是最早提出来通过双线性差值upsampling的方式实现end-to-end训练，生成与原图相同尺寸的语义分割map，并采用了fine-tune方法通过加载VGG16预先训练好的权重进行局部训练。Fcn针对不同尺度的细节表现和分割平滑，从encoder中的不同层提取相应的map进行组合的方式，实现综合finer和coarser部分。SegNet提出了一种对称结构的encoder-decoder网络，encoder部分省略了Vgg16的Full connected层。而在实际训练中，我们发现相较于前者，SegNet更难收敛，但是对细节的描述更加精准。而ENet主要的工作是采用留数网络ResNet的encoder结构，能够实现更快速的inference过程（训练较慢）。对于decoder部分，认为主要就是实现对原图尺寸的还原，平滑分割边界，因而采用了较小的网络结构（可能是Fcn32s的decoder部分）。最后，我们还参考了comma.ai上提出的方法，由于decoder的作用是尺度还原和平滑边界，可以采用较小的网络结构，他们使用的是一个16x5x5核，步长2的upscaling方法。&lt;/p&gt;

&lt;p&gt;[1] Liang-Chieh Chen, George Papandreou, Iasonas Kokkinos, Kevin Murphy, Alan L. Yuille &quot;Semantic Image Segmentation with Deep Convolutional Nets and Fully Connected CRFs&quot;. arXiv:1412.7062&lt;br/&gt;
[2] Vijay Badrinarayanan, Ankur Handa and Roberto Cipolla &quot;SegNet: A Deep Convolutional Encoder-Decoder Architecture for Robust Semantic Pixel-Wise Labelling&quot;. arXiv:1505.07293 &lt;br/&gt;
[3] Adam Paszke, Abhishek Chaurasia, Sangpil Kim, Eugenio Culurciello &quot;ENet: A Deep Neural Network Architecture for Real-Time Semantic Segmentation&quot;. arXiv:1606.02147.&lt;/p&gt;
</description>
        <pubDate>Wed, 27 Jul 2016 01:09:59 +0800</pubDate>
        <link>http://yourdomain.com/segmentation/2016/07/27/train-on-camvid.html</link>
        <guid isPermaLink="true">http://yourdomain.com/segmentation/2016/07/27/train-on-camvid.html</guid>
        
        
        <category>segmentation</category>
        
      </item>
    
      <item>
        <title>Train Overview</title>
        <description>&lt;p&gt;&lt;strong&gt;solver.prototxt参数说明&lt;/strong&gt;
train_net/test_net ： 网络定义文件的路径
test_iter : 如果数据库有1000个样本，batch_size为10，则需要100次iterations. 因而定义了test_iter，则表示测试阶段每次数据量batch_size
test_interval : 训练阶段，定义迭代的次数进行测试，如500次迭代一次测试
base_lr ： 初始学习速率
- fixed : 保持base_lr不变
- step ： 需设置stepsize, 返回base_lr * gamma ^ (floor(iter / stepsize))
- inv : 需设置power，返回base_lr * (1 + gamma&lt;em&gt;iter)&lt;sup&gt;-power&lt;/sup&gt;
- poly : 进行多项式误差，返回base_lr&lt;/em&gt;(1-iter/max_iter)&lt;sup&gt;power&lt;/sup&gt;
- sigmoid ： 进行sigmoid衰减，返回base_lr&lt;em&gt;(1/(1+exp(-gamma&lt;/em&gt;(iter-stepsize))))
momentum : 含该参数的sgd
weight_decay : 权重衰减
lr_policy : 学习参数的衰减方式
gamma, power
iter_size : 实际的batch_size等于iter_size x 网络定义的batch_size，因此每一次迭代的loss是iter_size次迭代的总和，再除以iter_size。如此设置是应对直接使用大batch_size会导致out of memory，借助这个方法可以使用较小的batch_size来完成实际上处理相同数据量的工作。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Training&lt;/strong&gt;&lt;br/&gt;
solver = caffe.SGDSolver(&quot;solver.prototxt&quot;)&lt;br/&gt;
如果进行fine-tune，则需要调用&lt;br/&gt;
solver.net.copy_from('xxx.caffemodel')
可以继续未完成的训练，通过调用&lt;br/&gt;
solver.restore('xxx.solverstate')&lt;/p&gt;

&lt;p&gt;在fine-tune过程中，参数设置如下实现训练过程对模型权重的更改。
param {&lt;br/&gt;
    lr_mult: 1&lt;br/&gt;
    decay_mult: 1&lt;br/&gt;
}&lt;br/&gt;
而param{lr_mult:0}表示为保留原有模型权重（载入模型）。&lt;/p&gt;

&lt;p&gt;example/net_surgery.ipynb是有效地介绍如何使用surgery的内容。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;训练过程：&lt;/strong&gt;
1）样本预处理，均值化
2）选择网络，ReLU
3）初始化权重（xavier）
4）babysitting the learning process
5）由cross到finer处理&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;接下来,：&lt;/strong&gt;
1）参数更新机制（adam，agagrad,）
2）学习速率调节
3）Dropout
4）梯度检查
5）模型聚合&lt;/p&gt;

&lt;p&gt;&lt;font color=#FF0000 size=4&gt;
&lt;strong&gt;Patchwise training is loss sampling&lt;/strong&gt;&lt;br/&gt;
Sampling in patchwise training can correct class imbalance, and mitigate the spatical correlation of dense patches. In fully convolutional training, class balance can also be achieved by weighting the loss, and loss sampling can be used to address spatial correlation.
&lt;strong&gt;Class Balancing&lt;/strong&gt;&lt;br/&gt;
Fully convolutional training can balance classes by weighting or sampling the loss. No need to balance class.
&lt;/font&gt;&lt;/p&gt;
</description>
        <pubDate>Wed, 27 Jul 2016 00:44:59 +0800</pubDate>
        <link>http://yourdomain.com/segmentation/2016/07/27/train-overview.html</link>
        <guid isPermaLink="true">http://yourdomain.com/segmentation/2016/07/27/train-overview.html</guid>
        
        
        <category>segmentation</category>
        
      </item>
    
  </channel>
</rss>
