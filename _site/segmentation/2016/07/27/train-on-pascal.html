<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width initial-scale=1">

  <title>Train on Pascal</title>
  <meta name="description" content="SegNet Training">

  <link rel="stylesheet" href="/css/main.css">
  <link rel="canonical" href="http://yourdomain.com/segmentation/2016/07/27/train-on-pascal.html">
  <link rel="alternate" type="application/atom+xml" title="Deep Learning Study" href="http://yourdomain.com/feed.xml" />
</head>


  <body>

    <header class="site-header">

  <div class="wrapper">

    <a class="site-title" href="/">Deep Learning Study</a>

    <nav class="site-nav">
      <a href="#" class="menu-icon">
        <svg viewBox="0 0 18 15">
          <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
          <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
          <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
        </svg>
      </a>

      <div class="trigger">
        
          
          <a class="page-link" href="/about/">About</a>
          
        
          
        
          
        
          
        
      </div>
    </nav>

  </div>

</header>


    <div class="page-content">
      <div class="wrapper">
        <div class="post">

  <header class="post-header">
    <h1 class="post-title">Train on Pascal</h1>
    <p class="post-meta">Jul 27, 2016</p>
  </header>

  <article class="post-content">
    <p>SegNet Training</p>

<p><strong>Step1. 不训练（没有反向过程），直接测试。</strong>
    1）不用pretrained模型
    2）使用pretrained模型
    其中，1）结果如下：
    »&gt; 2016-07-25 15:29:18.270980 Iteration 0 loss 87.3365001902
    »&gt; 2016-07-25 15:29:18.271152 Iteration 0 overall accuracy 0.733180213097
    »&gt; 2016-07-25 15:29:18.271215 Iteration 0 mean accuracy 0.047619047619
    »&gt; 2016-07-25 15:29:18.271508 Iteration 0 mean IU 0.0349133434808
    »&gt; 2016-07-25 15:29:18.271601 Iteration 0 fwavacc 0.537553224877
    相应，2）结果如下：
    »&gt; 2016-07-25 15:35:54.661197 Iteration 0 loss 87.3365001902
    »&gt; 2016-07-25 15:35:54.661321 Iteration 0 overall accuracy 0.733180213097
    »&gt; 2016-07-25 15:35:54.661488 Iteration 0 mean accuracy 0.047619047619
    »&gt; 2016-07-25 15:35:54.661621 Iteration 0 mean IU 0.0349133434808
    »&gt; 2016-07-25 15:35:54.661709 Iteration 0 fwavacc 0.537553224877
    很明显，无论是否采用vgg16对没有经过训练网络的结果没有影响。</p>

<p><strong>Step2. 训练，再测试。</strong>
    solver.protoxt中参数根据文章中的设置如下：
    train_net: “train.prototxt”
    test_net: “val.prototxt”
    test_initialization: false
    test_iter: 736
    test_interval: 999999999
    display: 20
    average_loss: 20
    lr_policy: “fixed”
    base_lr: 1e-4
    momentum: 0.9
    iter_size: 1 
    max_iter: 100000
    weight_decay: 0.0005
    snapshot: 4000
    snapshot_prefix: “snapshot/segnet”
    solver_mode: GPU</p>

<pre><code>1）使用pretrained VGG16模型，每次训练步长为4000，训练结果如下：
&gt;&gt;&gt; 2016-07-26 12:23:04.827459 Iteration 4000 loss 1.31175746871
&gt;&gt;&gt; 2016-07-26 12:23:04.827577 Iteration 4000 overall accuracy 0.733180213097
&gt;&gt;&gt; 2016-07-26 12:23:04.827639 Iteration 4000 mean accuracy 0.047619047619
&gt;&gt;&gt; 2016-07-26 12:23:04.827855 Iteration 4000 mean IU 0.0349133434808
&gt;&gt;&gt; 2016-07-26 12:23:04.828067 Iteration 4000 fwavacc 0.537553224877
在经过4000次迭代，大约2.5倍样本集后，发现loss在缓慢下降，但是其他测量结果没有改变。

&gt;&gt;&gt; 2016-07-26 17:29:48.209541 Iteration 48000 loss 1.56178289191
&gt;&gt;&gt; 2016-07-26 17:29:48.209808 Iteration 48000 overall accuracy 0.733170522908
&gt;&gt;&gt; 2016-07-26 17:29:48.209855 Iteration 48000 mean accuracy 0.0476187852268
&gt;&gt;&gt; 2016-07-26 17:29:48.209980 Iteration 48000 mean IU 0.0349132915075
&gt;&gt;&gt; 2016-07-26 17:29:48.210064 Iteration 48000 fwavacc 0.537546775601
在经过48000次迭代以后，loss并没有收敛，训练失败，待续。


Fcn32s Training
首先，我们下载了训练好的模型fcn32s-heavy-model，发现经过finetune以后，结果会更好。
Fcn32s fine-tune with pretrained heavy model 
&gt;&gt;&gt; 2016-07-11 17:09:09.316152 Begin seg tests
&gt;&gt;&gt; 2016-07-11 17:11:40.982484 Iteration 4000 loss 40536.5665925
&gt;&gt;&gt; 2016-07-11 17:11:40.982576 Iteration 4000 overall accuracy 0.924534222757
&gt;&gt;&gt; 2016-07-11 17:11:40.982608 Iteration 4000 mean accuracy 0.789070139032
&gt;&gt;&gt; 2016-07-11 17:11:40.982729 Iteration 4000 mean IU 0.68489801572
&gt;&gt;&gt; 2016-07-11 17:11:40.982804 Iteration 4000 fwavacc 0.867180920774

&gt;&gt;&gt; 2016-07-11 17:32:13.296804 Begin seg tests
&gt;&gt;&gt; 2016-07-11 17:34:39.726955 Iteration 8000 loss 40918.7736482
&gt;&gt;&gt; 2016-07-11 17:34:39.727035 Iteration 8000 overall accuracy 0.928679202249
&gt;&gt;&gt; 2016-07-11 17:34:39.727064 Iteration 8000 mean accuracy 0.812085149284
&gt;&gt;&gt; 2016-07-11 17:34:39.727181 Iteration 8000 mean IU 0.698756970877
&gt;&gt;&gt; 2016-07-11 17:34:39.727255 Iteration 8000 fwavacc 0.873438191274

Fcn32s + pretrained heavy model without training
&gt;&gt;&gt; 2016-07-11 17:38:19.174321 Begin seg tests
&gt;&gt;&gt; 2016-07-11 17:40:52.292152 Iteration 0 loss 45737.5351437
&gt;&gt;&gt; 2016-07-11 17:40:52.292247 Iteration 0 overall accuracy 0.926090782406
&gt;&gt;&gt; 2016-07-11 17:40:52.292278 Iteration 0 mean accuracy 0.817075271365
&gt;&gt;&gt; 2016-07-11 17:40:52.292399 Iteration 0 mean IU 0.695001155057
&gt;&gt;&gt; 2016-07-11 17:40:52.292475 Iteration 0 fwavacc 0.869301769793

其次，我们利用pretrained VGG16进行训练，目前得到的结果显示，loss会降低，但是其他测量结果并没有发生改变，如下：
&gt;&gt;&gt; 2016-07-26 12:48:33.904036 Iteration 8000 loss 3916726.69319
&gt;&gt;&gt; 2016-07-26 12:48:33.904141 Iteration 8000 overall accuracy 0.733180213097
&gt;&gt;&gt; 2016-07-26 12:48:33.904256 Iteration 8000 mean accuracy 0.047619047619
&gt;&gt;&gt; 2016-07-26 12:48:33.904529 Iteration 8000 mean IU 0.0349133434808
&gt;&gt;&gt; 2016-07-26 12:48:33.904619 Iteration 8000 fwavacc 0.53755322487

&gt;&gt;&gt; 2016-07-26 13:39:00.477857 Iteration 16000 loss 3646240.50901
&gt;&gt;&gt; 2016-07-26 13:39:00.477998 Iteration 16000 overall accuracy 0.733180213097
&gt;&gt;&gt; 2016-07-26 13:39:00.478118 Iteration 16000 mean accuracy 0.047619047619
&gt;&gt;&gt; 2016-07-26 13:39:00.478241 Iteration 16000 mean IU 0.0349133434808
&gt;&gt;&gt; 2016-07-26 13:39:00.478323 Iteration 16000 fwavacc 0.537553224877

&gt;&gt;&gt; 2016-07-26 17:03:43.480082 Iteration 48000 loss 3076769.60242
&gt;&gt;&gt; 2016-07-26 17:03:43.480186 Iteration 48000 overall accuracy 0.733180213097
&gt;&gt;&gt; 2016-07-26 17:03:43.480288 Iteration 48000 mean accuracy 0.047619047619
&gt;&gt;&gt; 2016-07-26 17:03:43.480508 Iteration 48000 mean IU 0.0349133434808
&gt;&gt;&gt; 2016-07-26 17:03:43.480592 Iteration 48000 fwavacc 0.537553224877
经过近50000次的训练，发现其中loss并没有收敛，而且另外4个指标也完全没有任何改变，和未经过训练的结果相同。可见，这里存在什么问题还没有弄清楚，待续。
</code></pre>


  </article>

</div>

      </div>
    </div>

    <footer class="site-footer">

  <div class="wrapper">

    <h2 class="footer-heading">Deep Learning Study</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col  footer-col-1">
        <ul class="contact-list">
          <li>Deep Learning Study</li>
          <li><a href="mailto:marshallixp@hotmail.com">marshallixp@hotmail.com</a></li>
        </ul>
      </div>

      <div class="footer-col  footer-col-2">
        <ul class="social-media-list">
          
          <li>
            <a href="https://github.com/marshallixp">
              <span class="icon  icon--github">
                <svg viewBox="0 0 16 16">
                  <path fill="#828282" d="M7.999,0.431c-4.285,0-7.76,3.474-7.76,7.761 c0,3.428,2.223,6.337,5.307,7.363c0.388,0.071,0.53-0.168,0.53-0.374c0-0.184-0.007-0.672-0.01-1.32 c-2.159,0.469-2.614-1.04-2.614-1.04c-0.353-0.896-0.862-1.135-0.862-1.135c-0.705-0.481,0.053-0.472,0.053-0.472 c0.779,0.055,1.189,0.8,1.189,0.8c0.692,1.186,1.816,0.843,2.258,0.645c0.071-0.502,0.271-0.843,0.493-1.037 C4.86,11.425,3.049,10.76,3.049,7.786c0-0.847,0.302-1.54,0.799-2.082C3.768,5.507,3.501,4.718,3.924,3.65 c0,0,0.652-0.209,2.134,0.796C6.677,4.273,7.34,4.187,8,4.184c0.659,0.003,1.323,0.089,1.943,0.261 c1.482-1.004,2.132-0.796,2.132-0.796c0.423,1.068,0.157,1.857,0.077,2.054c0.497,0.542,0.798,1.235,0.798,2.082 c0,2.981-1.814,3.637-3.543,3.829c0.279,0.24,0.527,0.713,0.527,1.437c0,1.037-0.01,1.874-0.01,2.129 c0,0.208,0.14,0.449,0.534,0.373c3.081-1.028,5.302-3.935,5.302-7.362C15.76,3.906,12.285,0.431,7.999,0.431z"/>
                </svg>
              </span>

              <span class="username">marshallixp</span>
            </a>
          </li>
          

          
        </ul>
      </div>

      <div class="footer-col  footer-col-3">
        <p class="text">Explain the state-of-art research and Track our latest experiments.
</p>
      </div>
    </div>

  </div>

</footer>


  </body>

</html>
