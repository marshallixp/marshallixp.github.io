<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width initial-scale=1">

  <title>Train on CamVid</title>
  <meta name="description" content="原有camvid拥有33个类：">

  <link rel="stylesheet" href="/css/main.css">
  <link rel="canonical" href="http://yourdomain.com/segmentation/2016/07/27/train-on-camvid.html">
  <link rel="alternate" type="application/atom+xml" title="Deep Learning Study" href="http://yourdomain.com/feed.xml" />
</head>


  <body>

    <header class="site-header">

  <div class="wrapper">

    <a class="site-title" href="/">Deep Learning Study</a>

    <nav class="site-nav">
      <a href="#" class="menu-icon">
        <svg viewBox="0 0 18 15">
          <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
          <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
          <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
        </svg>
      </a>

      <div class="trigger">
        
          
          <a class="page-link" href="/about/">About</a>
          
        
          
        
          
        
          
        
      </div>
    </nav>

  </div>

</header>


    <div class="page-content">
      <div class="wrapper">
        <div class="post">

  <header class="post-header">
    <h1 class="post-title">Train on CamVid</h1>
    <p class="post-meta">Jul 27, 2016</p>
  </header>

  <article class="post-content">
    <p>原有camvid拥有33个类：</p>

<p>64 128 64   Animal
192 0 128   Archway
0 128 192   Bicyclist
0 128 64    Bridge
128 0 0     Building
64 0 128    Car
64 0 192    CartLuggagePram
192 128 64  Child
192 192 128 Column_Pole
64 64 128   Fence
128 0 192   LaneMkgsDriv
192 0 64    LaneMkgsNonDriv
128 128 64  Misc_Text
192 0 192   MotorcycleScooter
128 64 64   OtherMoving
64 192 128  ParkingBlock
64 64 0     Pedestrian
128 64 128  Road
128 128 192 RoadShoulder
0 0 192     Sidewalk
192 128 128 SignSymbol
128 128 128 Sky
64 128 192  SUVPickupTruck
0 0 64      TrafficCone
0 64 64     TrafficLight
192 64 128  Train
128 128 0   Tree
192 128 192 Truck_Bus
64 0 64     Tunnel
192 192 0   VegetationMisc
0 0 0       Void
64 192 0    Wall</p>

<p><strong>SegNet postprocess</strong>
python /Segnet/Scripts/compute_bn_statistics.py /SegNet/Models/segnet_train.prototxt /SegNet/Models/Training/segnet_iter_10000.caffemodel /Segnet/Models/Inference/</p>

<p><strong>SegNet + Pretrained VGG16</strong></p>

<h1>Iteration 10000:</h1>

<p>Global acc = 0.85101 Class average acc = 0.46322 Mean Int over Union = 0.40203</p>

<h1>Iteration 20000:</h1>

<p>Global acc = 0.85167 Class average acc = 0.52274 Mean Int over Union = 0.44069</p>

<h1>Iteration 30000:</h1>

<p>Global acc = 0.85501 Class average acc = 0.5228 Mean Int over Union = 0.44517</p>

<p><strong>SegNet modified (修正crop层，可以自动实现不同层之间的匹配)</strong></p>

<h1>Iteration 26000:</h1>

<p>Global acc = 0.81241 Class average acc = 0.47571 Mean Int over Union = 0.3939
低于原有模型训练结果，或许跟参数设置有关系。</p>

<p><strong>Fcn32s + Pretrained VGG16</strong></p>

<h1>Iteration 56000:</h1>

<p>Global acc = 0.79462 Class average acc = 0.4331 Mean Int over Union = 0.35841</p>

<p><strong>Fcn8s + Pretrained VGG16</strong></p>

<h1>Iteration 56000:</h1>

<p>Global acc = 0.70828 Class average acc = 0.36595 Mean Int over Union = 0.28398</p>

<p><strong>总结：</strong>
在针对道路场景的语义分割训练中，我们主要参考了Fcn[1], SegNet[2], ENet[3]，这三篇文章。其中，Fcn是最早提出来通过双线性差值upsampling的方式实现end-to-end训练，生成与原图相同尺寸的语义分割map，并采用了fine-tune方法通过加载VGG16预先训练好的权重进行局部训练。Fcn针对不同尺度的细节表现和分割平滑，从encoder中的不同层提取相应的map进行组合的方式，实现综合finer和coarser部分。SegNet提出了一种对称结构的encoder-decoder网络，encoder部分省略了Vgg16的Full connected层。而在实际训练中，我们发现相较于前者，SegNet更难收敛，但是对细节的描述更加精准。而ENet主要的工作是采用留数网络ResNet的encoder结构，能够实现更快速的inference过程（训练较慢）。对于decoder部分，认为主要就是实现对原图尺寸的还原，平滑分割边界，因而采用了较小的网络结构（可能是Fcn的decoder部分）。最后，我们还参考了comma.ai上提出的方法，由于decoder的作用是尺度还原和平滑边界，可以采用较小的网络结构，他们使用的是一个16x5x5核，步长2的upscaling方法。</p>

<p>[1] Liang-Chieh Chen, George Papandreou, Iasonas Kokkinos, Kevin Murphy, Alan L. Yuille "Semantic Image Segmentation with Deep Convolutional Nets and Fully Connected CRFs". arXiv:1412.7062<br/>
[2] Vijay Badrinarayanan, Ankur Handa and Roberto Cipolla "SegNet: A Deep Convolutional Encoder-Decoder Architecture for Robust Semantic Pixel-Wise Labelling". arXiv:1505.07293 <br/>
[3] Adam Paszke, Abhishek Chaurasia, Sangpil Kim, Eugenio Culurciello "ENet: A Deep Neural Network Architecture for Real-Time Semantic Segmentation". arXiv:1606.02147.</p>

  </article>

</div>

      </div>
    </div>

    <footer class="site-footer">

  <div class="wrapper">

    <h2 class="footer-heading">Deep Learning Study</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col  footer-col-1">
        <ul class="contact-list">
          <li>Deep Learning Study</li>
          <li><a href="mailto:marshallixp@hotmail.com">marshallixp@hotmail.com</a></li>
        </ul>
      </div>

      <div class="footer-col  footer-col-2">
        <ul class="social-media-list">
          
          <li>
            <a href="https://github.com/marshallixp">
              <span class="icon  icon--github">
                <svg viewBox="0 0 16 16">
                  <path fill="#828282" d="M7.999,0.431c-4.285,0-7.76,3.474-7.76,7.761 c0,3.428,2.223,6.337,5.307,7.363c0.388,0.071,0.53-0.168,0.53-0.374c0-0.184-0.007-0.672-0.01-1.32 c-2.159,0.469-2.614-1.04-2.614-1.04c-0.353-0.896-0.862-1.135-0.862-1.135c-0.705-0.481,0.053-0.472,0.053-0.472 c0.779,0.055,1.189,0.8,1.189,0.8c0.692,1.186,1.816,0.843,2.258,0.645c0.071-0.502,0.271-0.843,0.493-1.037 C4.86,11.425,3.049,10.76,3.049,7.786c0-0.847,0.302-1.54,0.799-2.082C3.768,5.507,3.501,4.718,3.924,3.65 c0,0,0.652-0.209,2.134,0.796C6.677,4.273,7.34,4.187,8,4.184c0.659,0.003,1.323,0.089,1.943,0.261 c1.482-1.004,2.132-0.796,2.132-0.796c0.423,1.068,0.157,1.857,0.077,2.054c0.497,0.542,0.798,1.235,0.798,2.082 c0,2.981-1.814,3.637-3.543,3.829c0.279,0.24,0.527,0.713,0.527,1.437c0,1.037-0.01,1.874-0.01,2.129 c0,0.208,0.14,0.449,0.534,0.373c3.081-1.028,5.302-3.935,5.302-7.362C15.76,3.906,12.285,0.431,7.999,0.431z"/>
                </svg>
              </span>

              <span class="username">marshallixp</span>
            </a>
          </li>
          

          
        </ul>
      </div>

      <div class="footer-col  footer-col-3">
        <p class="text">Explain the state-of-art research and Track our latest experiments.
</p>
      </div>
    </div>

  </div>

</footer>


  </body>

</html>
